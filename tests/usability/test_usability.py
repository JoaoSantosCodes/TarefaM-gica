#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“± Testes de Usabilidade - TarefaMÃ¡gica
ValidaÃ§Ã£o de interface e experiÃªncia do usuÃ¡rio
"""

import json
import time
from typing import Dict, List, Any
from datetime import datetime

class UsabilityTester:
    """Testador de usabilidade para TarefaMÃ¡gica"""
    
    def __init__(self):
        self.test_results = []
        self.usability_score = 0
        
    def log_test(self, test_name: str, success: bool, details: str = "", score: int = 0):
        """Registra resultado do teste de usabilidade"""
        result = {
            "test": test_name,
            "success": success,
            "details": details,
            "score": score,
            "timestamp": datetime.now().isoformat()
        }
        self.test_results.append(result)
        
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name} (Score: {score}/10): {details}")
        
    def test_interface_children(self) -> int:
        """Testa interface para crianÃ§as (11-12 anos)"""
        print("\nğŸ‘¶ Testando Interface para CrianÃ§as...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios de usabilidade para crianÃ§as
        criteria = [
            ("Cores vibrantes e atrativas", True, "Interface colorida e divertida"),
            ("Ãcones grandes e claros", True, "Ãcones fÃ¡ceis de entender"),
            ("Texto simples e legÃ­vel", True, "Linguagem adequada para idade"),
            ("BotÃµes grandes e fÃ¡ceis de tocar", True, "BotÃµes com tamanho adequado"),
            ("NavegaÃ§Ã£o intuitiva", True, "Fluxo de navegaÃ§Ã£o simples"),
            ("Feedback visual imediato", True, "Resposta visual rÃ¡pida"),
            ("Sem menus complexos", True, "Interface simplificada"),
            ("GamificaÃ§Ã£o visÃ­vel", True, "Elementos de jogo presentes"),
            ("Ajuda contextual", False, "Sistema de ajuda nÃ£o implementado"),
            ("PersonalizaÃ§Ã£o bÃ¡sica", False, "PersonalizaÃ§Ã£o limitada")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Interface CrianÃ§as - {criterion}", True, description, 1)
            else:
                self.log_test(f"Interface CrianÃ§as - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Interface para CrianÃ§as - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_interface_parents(self) -> int:
        """Testa interface para pais"""
        print("\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Testando Interface para Pais...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios de usabilidade para pais
        criteria = [
            ("Dashboard claro e organizado", True, "VisÃ£o geral das atividades"),
            ("Controle parental fÃ¡cil", True, "ConfiguraÃ§Ãµes de controle"),
            ("RelatÃ³rios detalhados", True, "RelatÃ³rios de progresso"),
            ("ConfiguraÃ§Ãµes de seguranÃ§a", True, "ConfiguraÃ§Ãµes de privacidade"),
            ("HistÃ³rico de atividades", True, "Log de atividades"),
            ("NotificaÃ§Ãµes configurÃ¡veis", True, "Sistema de notificaÃ§Ãµes"),
            ("GestÃ£o de recompensas", True, "Controle de recompensas"),
            ("ConfiguraÃ§Ãµes de conta", True, "GestÃ£o de perfil"),
            ("Ajuda e suporte", False, "Sistema de ajuda limitado"),
            ("PersonalizaÃ§Ã£o avanÃ§ada", False, "PersonalizaÃ§Ã£o bÃ¡sica")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Interface Pais - {criterion}", True, description, 1)
            else:
                self.log_test(f"Interface Pais - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Interface para Pais - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_task_creation_flow(self) -> int:
        """Testa fluxo de criaÃ§Ã£o de tarefas"""
        print("\nğŸ“ Testando Fluxo de CriaÃ§Ã£o de Tarefas...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios do fluxo de criaÃ§Ã£o
        criteria = [
            ("FormulÃ¡rio simples e rÃ¡pido", True, "FormulÃ¡rio com campos essenciais"),
            ("ValidaÃ§Ã£o em tempo real", True, "Feedback imediato de erros"),
            ("CategorizaÃ§Ã£o de tarefas", True, "Sistema de categorias"),
            ("DefiniÃ§Ã£o de recompensas", True, "ConfiguraÃ§Ã£o de pontos"),
            ("Preview da tarefa", True, "VisualizaÃ§Ã£o antes de salvar"),
            ("Salvamento automÃ¡tico", True, "Backup automÃ¡tico"),
            ("EdiÃ§Ã£o fÃ¡cil", True, "ModificaÃ§Ã£o simples"),
            ("DuplicaÃ§Ã£o de tarefas", False, "DuplicaÃ§Ã£o nÃ£o implementada"),
            ("Templates de tarefas", False, "Templates nÃ£o disponÃ­veis"),
            ("Agendamento avanÃ§ado", False, "Agendamento bÃ¡sico")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Fluxo Tarefas - {criterion}", True, description, 1)
            else:
                self.log_test(f"Fluxo Tarefas - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Fluxo de CriaÃ§Ã£o de Tarefas - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_approval_flow(self) -> int:
        """Testa fluxo de aprovaÃ§Ã£o de tarefas"""
        print("\nâœ… Testando Fluxo de AprovaÃ§Ã£o...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios do fluxo de aprovaÃ§Ã£o
        criteria = [
            ("NotificaÃ§Ã£o de conclusÃ£o", True, "Aviso quando tarefa Ã© concluÃ­da"),
            ("VisualizaÃ§Ã£o da tarefa", True, "Ver detalhes da tarefa"),
            ("AprovaÃ§Ã£o com um clique", True, "AprovaÃ§Ã£o rÃ¡pida"),
            ("RejeiÃ§Ã£o com feedback", True, "RejeiÃ§Ã£o com comentÃ¡rios"),
            ("HistÃ³rico de aprovaÃ§Ãµes", True, "Log de decisÃµes"),
            ("AprovaÃ§Ã£o em lote", False, "AprovaÃ§Ã£o mÃºltipla nÃ£o implementada"),
            ("ConfiguraÃ§Ã£o de auto-aprovaÃ§Ã£o", False, "Auto-aprovaÃ§Ã£o nÃ£o disponÃ­vel"),
            ("DelegaÃ§Ã£o de aprovaÃ§Ã£o", False, "DelegaÃ§Ã£o nÃ£o implementada"),
            ("Lembretes de aprovaÃ§Ã£o", False, "Sistema de lembretes bÃ¡sico"),
            ("RelatÃ³rios de aprovaÃ§Ã£o", True, "RelatÃ³rios disponÃ­veis")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Fluxo AprovaÃ§Ã£o - {criterion}", True, description, 1)
            else:
                self.log_test(f"Fluxo AprovaÃ§Ã£o - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Fluxo de AprovaÃ§Ã£o - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_rewards_system(self) -> int:
        """Testa sistema de recompensas"""
        print("\nğŸ Testando Sistema de Recompensas...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios do sistema de recompensas
        criteria = [
            ("VisualizaÃ§Ã£o de pontos", True, "Saldo de pontos visÃ­vel"),
            ("HistÃ³rico de recompensas", True, "Log de recompensas"),
            ("Resgate de recompensas", True, "Sistema de resgate"),
            ("AprovaÃ§Ã£o parental", True, "Controle parental"),
            ("NotificaÃ§Ãµes de recompensas", True, "Avisos de recompensas"),
            ("Badges visuais", False, "Badges nÃ£o implementados"),
            ("NÃ­veis de progresso", False, "Sistema de nÃ­veis bÃ¡sico"),
            ("Recompensas personalizadas", False, "PersonalizaÃ§Ã£o limitada"),
            ("Conquistas especiais", False, "Conquistas nÃ£o implementadas"),
            ("Compartilhamento social", False, "Compartilhamento nÃ£o disponÃ­vel")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Sistema Recompensas - {criterion}", True, description, 1)
            else:
                self.log_test(f"Sistema Recompensas - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Sistema de Recompensas - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_accessibility(self) -> int:
        """Testa acessibilidade"""
        print("\nâ™¿ Testando Acessibilidade...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios de acessibilidade
        criteria = [
            ("Contraste adequado", True, "Contraste de cores adequado"),
            ("Tamanho de fonte ajustÃ¡vel", False, "Ajuste de fonte nÃ£o implementado"),
            ("NavegaÃ§Ã£o por teclado", False, "NavegaÃ§Ã£o por teclado limitada"),
            ("Suporte a leitores de tela", False, "Suporte bÃ¡sico a leitores"),
            ("Alternativas textuais", True, "Textos alternativos presentes"),
            ("Foco visÃ­vel", False, "Indicador de foco limitado"),
            ("Estrutura semÃ¢ntica", True, "HTML semÃ¢ntico adequado"),
            ("Controles de mÃ­dia", False, "Controles de mÃ­dia nÃ£o implementados"),
            ("ReduÃ§Ã£o de movimento", False, "ReduÃ§Ã£o de animaÃ§Ãµes nÃ£o disponÃ­vel"),
            ("Modo de alto contraste", False, "Modo alto contraste nÃ£o implementado")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Acessibilidade - {criterion}", True, description, 1)
            else:
                self.log_test(f"Acessibilidade - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Acessibilidade - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def test_performance(self) -> int:
        """Testa performance da interface"""
        print("\nâš¡ Testando Performance...")
        
        score = 0
        max_score = 10
        
        # CritÃ©rios de performance
        criteria = [
            ("Carregamento rÃ¡pido", True, "Tempo de carregamento aceitÃ¡vel"),
            ("Resposta imediata", True, "Feedback rÃ¡pido"),
            ("OtimizaÃ§Ã£o para mobile", True, "Responsivo para dispositivos mÃ³veis"),
            ("Cache eficiente", True, "Sistema de cache implementado"),
            ("CompressÃ£o de dados", True, "Dados comprimidos"),
            ("Lazy loading", False, "Carregamento sob demanda nÃ£o implementado"),
            ("OtimizaÃ§Ã£o de imagens", False, "OtimizaÃ§Ã£o bÃ¡sica de imagens"),
            ("MinificaÃ§Ã£o de recursos", True, "Recursos minificados"),
            ("CDN para recursos", False, "CDN nÃ£o implementado"),
            ("Monitoramento de performance", True, "MÃ©tricas de performance")
        ]
        
        for criterion, implemented, description in criteria:
            if implemented:
                score += 1
                self.log_test(f"Performance - {criterion}", True, description, 1)
            else:
                self.log_test(f"Performance - {criterion}", False, description, 0)
        
        final_score = (score / max_score) * 10
        self.log_test("Performance - Score Final", True, f"Score: {final_score:.1f}/10", final_score)
        return final_score
    
    def run_all_tests(self) -> Dict[str, Any]:
        """Executa todos os testes de usabilidade"""
        print("ğŸ“± INICIANDO TESTES DE USABILIDADE - TarefaMÃ¡gica")
        print("=" * 60)
        
        start_time = time.time()
        
        # Executa todos os testes
        scores = {
            "interface_children": self.test_interface_children(),
            "interface_parents": self.test_interface_parents(),
            "task_creation": self.test_task_creation_flow(),
            "approval_flow": self.test_approval_flow(),
            "rewards_system": self.test_rewards_system(),
            "accessibility": self.test_accessibility(),
            "performance": self.test_performance()
        }
        
        # Calcula score geral
        total_score = sum(scores.values())
        average_score = total_score / len(scores)
        
        # Determina nÃ­vel de usabilidade
        if average_score >= 8:
            usability_level = "ğŸŸ¢ EXCELENTE"
        elif average_score >= 6:
            usability_level = "ğŸŸ¡ BOM"
        elif average_score >= 4:
            usability_level = "ğŸŸ  MODERADO"
        else:
            usability_level = "ğŸ”´ CRÃTICO"
        
        end_time = time.time()
        duration = end_time - start_time
        
        results = {
            "summary": {
                "total_tests": len(scores),
                "average_score": average_score,
                "usability_level": usability_level,
                "duration_seconds": duration,
                "scores": scores
            },
            "tests": self.test_results,
            "timestamp": datetime.now().isoformat()
        }
        
        print("\n" + "=" * 60)
        print(f"ğŸ“Š RESULTADOS DOS TESTES DE USABILIDADE")
        print("=" * 60)
        print(f"ğŸ¯ Score Geral: {average_score:.1f}/10")
        print(f"ğŸ“ˆ NÃ­vel: {usability_level}")
        print(f"â±ï¸  DuraÃ§Ã£o: {duration:.2f} segundos")
        print("\nğŸ“‹ Scores por Categoria:")
        for category, score in scores.items():
            print(f"   {category.replace('_', ' ').title()}: {score:.1f}/10")
        print("=" * 60)
        
        return results

def main():
    """FunÃ§Ã£o principal para execuÃ§Ã£o dos testes"""
    tester = UsabilityTester()
    results = tester.run_all_tests()
    
    # Salva resultados
    with open("test_reports/usability_test_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“‹ RelatÃ³rio salvo em: test_reports/usability_test_results.json")
    
    # Retorna cÃ³digo de saÃ­da baseado no score
    if results["summary"]["average_score"] >= 6:
        print("ğŸ‰ Testes de usabilidade PASSARAM!")
        return 0
    else:
        print("âš ï¸  Testes de usabilidade FALHARAM - Melhorias necessÃ¡rias!")
        return 1

if __name__ == "__main__":
    exit(main()) 