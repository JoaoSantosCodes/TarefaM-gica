#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ Script de ValidaÃ§Ã£o Completa - TarefaMÃ¡gica
Executa todos os testes de validaÃ§Ã£o e gera relatÃ³rio final
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, Any

def run_security_tests():
    """Executa testes de seguranÃ§a"""
    print("ğŸ”’ Executando testes de seguranÃ§a...")
    
    try:
        from tests.security.test_penetration import PenetrationTester
        
        tester = PenetrationTester()
        results = tester.run_all_tests()
        
        return {
            "success": True,
            "results": results,
            "score": results["summary"]["security_score"]
        }
    except Exception as e:
        print(f"âŒ Erro nos testes de seguranÃ§a: {e}")
        return {
            "success": False,
            "error": str(e),
            "score": 0
        }

def run_usability_tests():
    """Executa testes de usabilidade"""
    print("ğŸ“± Executando testes de usabilidade...")
    
    try:
        from tests.usability.test_usability import UsabilityTester
        
        tester = UsabilityTester()
        results = tester.run_all_tests()
        
        return {
            "success": True,
            "results": results,
            "score": results["summary"]["average_score"]
        }
    except Exception as e:
        print(f"âŒ Erro nos testes de usabilidade: {e}")
        return {
            "success": False,
            "error": str(e),
            "score": 0
        }

def run_unit_tests():
    """Executa testes unitÃ¡rios"""
    print("ğŸ§ª Executando testes unitÃ¡rios...")
    
    try:
        import subprocess
        
        result = subprocess.run(
            ["python", "-m", "pytest", "tests/", "-v", "--json-report"],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode == 0:
            return {
                "success": True,
                "output": result.stdout,
                "score": 100
            }
        else:
            return {
                "success": False,
                "output": result.stderr,
                "score": 0
            }
    except Exception as e:
        print(f"âŒ Erro nos testes unitÃ¡rios: {e}")
        return {
            "success": False,
            "error": str(e),
            "score": 0
        }

def generate_final_report(security_results, usability_results, unit_results):
    """Gera relatÃ³rio final de validaÃ§Ã£o"""
    
    print("\nğŸ“Š Gerando relatÃ³rio final...")
    
    # Calcula scores
    security_score = security_results.get("score", 0)
    usability_score = usability_results.get("score", 0)
    unit_score = unit_results.get("score", 0)
    
    # Score geral (ponderado)
    overall_score = (security_score * 0.4 + usability_score * 0.3 + unit_score * 0.3)
    
    # Determina status geral
    if overall_score >= 90:
        status = "ğŸŸ¢ EXCELENTE"
        recommendation = "Projeto pronto para produÃ§Ã£o"
    elif overall_score >= 80:
        status = "ğŸŸ¡ BOM"
        recommendation = "Pequenas melhorias recomendadas"
    elif overall_score >= 70:
        status = "ğŸŸ  MODERADO"
        recommendation = "Melhorias necessÃ¡rias antes da produÃ§Ã£o"
    else:
        status = "ğŸ”´ CRÃTICO"
        recommendation = "CorreÃ§Ãµes crÃ­ticas necessÃ¡rias"
    
    # Identifica Ã¡reas que precisam de atenÃ§Ã£o
    areas_for_improvement = []
    if security_score < 80:
        areas_for_improvement.append("SeguranÃ§a")
    if usability_score < 70:
        areas_for_improvement.append("Usabilidade")
    if unit_score < 90:
        areas_for_improvement.append("Testes UnitÃ¡rios")
    
    report = {
        "validation_summary": {
            "timestamp": datetime.now().isoformat(),
            "overall_score": overall_score,
            "status": status,
            "recommendation": recommendation,
            "areas_for_improvement": areas_for_improvement
        },
        "detailed_scores": {
            "security": {
                "score": security_score,
                "status": "âœ… PASSOU" if security_score >= 80 else "âŒ FALHOU",
                "details": security_results
            },
            "usability": {
                "score": usability_score,
                "status": "âœ… PASSOU" if usability_score >= 70 else "âŒ FALHOU",
                "details": usability_results
            },
            "unit_tests": {
                "score": unit_score,
                "status": "âœ… PASSOU" if unit_score >= 90 else "âŒ FALHOU",
                "details": unit_results
            }
        },
        "next_steps": generate_next_steps(security_score, usability_score, unit_score)
    }
    
    return report

def generate_next_steps(security_score, usability_score, unit_score):
    """Gera prÃ³ximos passos baseado nos resultados"""
    
    next_steps = []
    
    if security_score < 80:
        next_steps.extend([
            "Implementar testes de penetraÃ§Ã£o adicionais",
            "Revisar configuraÃ§Ãµes de seguranÃ§a",
            "Validar compliance LGPD",
            "Implementar headers de seguranÃ§a adicionais"
        ])
    
    if usability_score < 70:
        next_steps.extend([
            "Melhorar interface para crianÃ§as",
            "Implementar sistema de ajuda",
            "Adicionar funcionalidades de acessibilidade",
            "Otimizar fluxo de criaÃ§Ã£o de tarefas"
        ])
    
    if unit_score < 90:
        next_steps.extend([
            "Aumentar cobertura de testes",
            "Corrigir testes falhando",
            "Implementar testes de integraÃ§Ã£o",
            "Adicionar testes de performance"
        ])
    
    if not next_steps:
        next_steps.append("Projeto pronto para prÃ³xima fase de desenvolvimento")
    
    return next_steps

def save_report(report, filename="validation_report.json"):
    """Salva relatÃ³rio em arquivo"""
    
    # Cria diretÃ³rio se nÃ£o existir
    os.makedirs("test_reports", exist_ok=True)
    
    filepath = os.path.join("test_reports", filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    return filepath

def print_summary(report):
    """Imprime resumo dos resultados"""
    
    print("\n" + "=" * 80)
    print("ğŸ¯ RELATÃ“RIO FINAL DE VALIDAÃ‡ÃƒO - TarefaMÃ¡gica")
    print("=" * 80)
    
    summary = report["validation_summary"]
    scores = report["detailed_scores"]
    
    print(f"ğŸ“Š Score Geral: {summary['overall_score']:.1f}/100")
    print(f"ğŸ¯ Status: {summary['status']}")
    print(f"ğŸ’¡ RecomendaÃ§Ã£o: {summary['recommendation']}")
    
    print(f"\nğŸ“‹ Scores Detalhados:")
    print(f"   ğŸ”’ SeguranÃ§a: {scores['security']['score']:.1f}/100 - {scores['security']['status']}")
    print(f"   ğŸ“± Usabilidade: {scores['usability']['score']:.1f}/100 - {scores['usability']['status']}")
    print(f"   ğŸ§ª Testes UnitÃ¡rios: {scores['unit_tests']['score']:.1f}/100 - {scores['unit_tests']['status']}")
    
    if summary['areas_for_improvement']:
        print(f"\nâš ï¸  Ãreas que Precisam de Melhoria:")
        for area in summary['areas_for_improvement']:
            print(f"   - {area}")
    
    print(f"\nğŸ“‹ PrÃ³ximos Passos:")
    for i, step in enumerate(report['next_steps'], 1):
        print(f"   {i}. {step}")
    
    print("=" * 80)

def main():
    """FunÃ§Ã£o principal"""
    
    print("ğŸ¯ INICIANDO VALIDAÃ‡ÃƒO COMPLETA - TarefaMÃ¡gica")
    print("=" * 60)
    
    start_time = time.time()
    
    # Executa todos os testes
    print("ğŸš€ Executando bateria completa de testes...")
    
    security_results = run_security_tests()
    usability_results = run_usability_tests()
    unit_results = run_unit_tests()
    
    # Gera relatÃ³rio final
    report = generate_final_report(security_results, usability_results, unit_results)
    
    # Salva relatÃ³rio
    filepath = save_report(report)
    
    # Imprime resumo
    print_summary(report)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nâ±ï¸  Tempo total de execuÃ§Ã£o: {duration:.2f} segundos")
    print(f"ğŸ“‹ RelatÃ³rio completo salvo em: {filepath}")
    
    # Retorna cÃ³digo de saÃ­da
    overall_score = report["validation_summary"]["overall_score"]
    
    if overall_score >= 80:
        print("\nğŸ‰ VALIDAÃ‡ÃƒO PASSOU! Projeto estÃ¡ pronto para prÃ³xima fase.")
        return 0
    else:
        print("\nâš ï¸  VALIDAÃ‡ÃƒO FALHOU! CorreÃ§Ãµes necessÃ¡rias antes de prosseguir.")
        return 1

if __name__ == "__main__":
    exit(main()) 